import streamlit as st
import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from scipy import stats
from PIL import Image, ImageOps

# ==========================================
# 1. è¾…åŠ©ç®—æ³•ï¼šä¸€ç»´ K-Means èšç±» (ç”¨äºæŠ—å€¾æ–œåˆ†è¡Œ)
# ==========================================
def simple_kmeans_1d(values, k, max_iter=100):
    """
    æ‰‹åŠ¨å®ç°ç®€å•çš„ä¸€ç»´ K-Meansï¼Œç”¨äºå°†åœ†å¿ƒçš„ Y åæ ‡åˆ†æˆ k ç±»ï¼ˆå³ k è¡Œï¼‰ã€‚
    è¿™æ¯”ç®€å•çš„é˜ˆå€¼åˆ‡åˆ†æ›´èƒ½æŠµæŠ—å›¾ç‰‡å€¾æ–œã€‚
    """
    if len(values) < k: return [0] * len(values)
    
    # åˆå§‹åŒ–ä¸­å¿ƒç‚¹ (å‡åŒ€åˆ†å¸ƒ)
    values = np.array(values)
    min_v, max_v = np.min(values), np.max(values)
    centroids = np.linspace(min_v, max_v, k)
    
    for _ in range(max_iter):
        # 1. åˆ†é…ç°‡
        # è®¡ç®—æ¯ä¸ªç‚¹åˆ°å„ä¸ªä¸­å¿ƒçš„è·ç¦»ï¼Œå–æœ€å°çš„ç´¢å¼•
        distances = np.abs(values[:, np.newaxis] - centroids)
        labels = np.argmin(distances, axis=1)
        
        # 2. æ›´æ–°ä¸­å¿ƒ
        new_centroids = np.array([values[labels == i].mean() if np.sum(labels == i) > 0 else centroids[i] 
                                  for i in range(k)])
        
        # æ”¶æ•›æ£€æµ‹
        if np.allclose(centroids, new_centroids):
            break
        centroids = new_centroids
        
    # å¯¹ centroids æ’åºï¼Œç¡®ä¿ label 0 æ˜¯æœ€ä¸Šé¢ä¸€è¡Œï¼Œlabel 1 æ˜¯ä¸‹ä¸€è¡Œ...
    sorted_indices = np.argsort(centroids)
    map_label = {old_idx: new_idx for new_idx, old_idx in enumerate(sorted_indices)}
    final_labels = [map_label[l] for l in labels]
    
    return final_labels

# ==========================================
# 2. æ ¸å¿ƒå›¾åƒå¤„ç†
# ==========================================
def process_image(img_file_buffer, rows, cols, required_count=None, analysis_mode="Saturation (S)"):
    # 1. å›¾åƒæ ‡å‡†åŒ–
    image_pil = Image.open(img_file_buffer)
    image_pil = ImageOps.exif_transpose(image_pil)
    target_width = 1000
    w_percent = (target_width / float(image_pil.size[0]))
    h_size = int((float(image_pil.size[1]) * float(w_percent)))
    image_pil = image_pil.resize((target_width, h_size), Image.Resampling.LANCZOS)
    img = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
    
    output_img = img.copy()
    
    # 2. åŠ¨æ€å‚æ•°
    approx_diameter = target_width / (cols + 0.5)
    dynamic_min_r = int(approx_diameter / 2 * 0.7)
    dynamic_max_r = int(approx_diameter / 2 * 1.2)
    min_dist_param = int(approx_diameter * 0.8) # ä¸¥é˜²é‡å 
    
    # 3. éœå¤«æ£€æµ‹
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced_gray = clahe.apply(gray)
    gray_blur = cv2.GaussianBlur(enhanced_gray, (9, 9), 2)

    circles = cv2.HoughCircles(
        gray_blur, cv2.HOUGH_GRADIENT, dp=1, 
        minDist=min_dist_param,
        param1=50, param2=25,
        minRadius=dynamic_min_r, 
        maxRadius=dynamic_max_r
    )

    s_values = []
    final_circles = []

    if circles is not None:
        circles = np.round(circles[0, :]).astype("int")
        
        # --- æ­¥éª¤ A: é¢œè‰²æ‰“åˆ† (ä¼˜èƒœåŠ£æ±°) ---
        # å‡†å¤‡é¢œè‰²é€šé“
        if "Saturation" in analysis_mode:
            score_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)[:,:,1]
        elif "Value" in analysis_mode:
            score_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)[:,:,2]
        elif "Red" in analysis_mode: score_img = img[:,:,2]
        elif "Green" in analysis_mode: score_img = img[:,:,1]
        elif "Blue" in analysis_mode: score_img = img[:,:,0]
        else: score_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        candidates = []
        for (x, y, r) in circles:
            if y < 0 or x < 0 or y >= img.shape[0] or x >= img.shape[1]: continue
            mask = np.zeros(img.shape[:2], dtype="uint8")
            # åªå–åœ†å¿ƒæœ€ä¸­é—´çš„ 40% è®¡ç®—åˆ†æ•°ï¼Œé¿å¼€è¾¹ç¼˜åå…‰
            cv2.circle(mask, (x, y), int(r * 0.4), 255, -1)
            score = cv2.mean(score_img, mask=mask)[0]
            candidates.append({'data': (x, y, r), 'score': score})
        
        # æŒ‰åˆ†æ•°æ’åºï¼Œå–å‰ N ä¸ª
        # å³ä½¿å›¾ç‰‡é‡Œæ‰¾åˆ°äº† 50 ä¸ªåœˆï¼Œæˆ‘ä»¬åªå–æœ€åƒå­”çš„ N ä¸ª
        candidates.sort(key=lambda k: k['score'], reverse=True)
        target_n = required_count if (required_count and required_count > 0) else (rows * cols)
        if len(candidates) > target_n:
            candidates = candidates[:target_n]
        
        accepted_circles = [c['data'] for c in candidates]
        
        # --- æ­¥éª¤ B: æ™ºèƒ½èšç±»åˆ†è¡Œ (K-Means Clustering) ---
        # è¿™æ˜¯è§£å†³å›¾ç‰‡æ­ªæ–œçš„æ ¸å¿ƒï¼ä¸æŒ‰ç»å¯¹Yåˆ‡åˆ†ï¼Œè€Œæ˜¯æŒ‰èšç±»åˆ‡åˆ†ã€‚
        if len(accepted_circles) > 0:
            y_coords = [c[1] for c in accepted_circles]
            # è°ƒç”¨è‡ªå®šä¹‰ K-Meansï¼ŒæŠŠ Y åæ ‡åˆ†æˆ 'rows' ä¸ªç°‡
            # æ³¨æ„ï¼šå¦‚æœå®é™…å­”æ•°å¾ˆå°‘ï¼ˆæ¯”å¦‚åªæœ‰ä¸€è¡Œï¼‰ï¼Œå¼ºè¡Œèšæˆ2ç±»å¯èƒ½ä¼šæœ‰é—®é¢˜
            # æ‰€ä»¥è¿™é‡Œåšä¸€ä¸ªä¿æŠ¤ï¼šå¦‚æœ target_n å¾ˆå°ï¼Œå°±åªèšç±»æˆ 1 è¡Œ
            k_rows = rows if len(accepted_circles) >= rows else 1
            labels = simple_kmeans_1d(y_coords, k_rows)
            
            # ç»„è£…å¸¦è¡Œå·çš„æ•°æ®: (row_idx, x, y, r)
            circles_with_row = []
            for i, c in enumerate(accepted_circles):
                circles_with_row.append((labels[i], c[0], c[1], c[2]))
            
            # --- æ­¥éª¤ C: æ’åº (å…ˆæŒ‰è¡Œå·æ’ï¼Œå†æŒ‰ X æ’) ---
            # 1. å…ˆæŒ‰è¡Œå·æ’åº
            circles_with_row.sort(key=lambda x: x[0])
            
            # 2. åŒä¸€è¡Œå†…ï¼ŒæŒ‰ X æ’åº
            final_circles = []
            current_row_idx = circles_with_row[0][0]
            current_row_circles = []
            
            for item in circles_with_row:
                r_idx, x, y, r = item
                if r_idx != current_row_idx:
                    # ç»“ç®—ä¸Šä¸€è¡Œ
                    current_row_circles.sort(key=lambda x: x[0])
                    final_circles.extend([(c[1], c[2], c[3]) for c in current_row_circles])
                    # å¼€å¯æ–°ä¸€è¡Œ
                    current_row_idx = r_idx
                    current_row_circles = []
                current_row_circles.append(item)
            
            # ç»“ç®—æœ€åä¸€è¡Œ
            current_row_circles.sort(key=lambda x: x[0]) # æŒ‰ X åæ ‡ (index 1) æ’åº
            final_circles.extend([(c[1], c[2], c[3]) for c in current_row_circles])
        
        # --- æ­¥éª¤ D: å–å€¼ä¸ç”»å›¾ ---
        roi_scale = 0.7 
        for i, (x, y, r) in enumerate(final_circles):
            # ç”»å›¾
            draw_r = int(r * roi_scale)
            cv2.circle(output_img, (x, y), draw_r, (0, 255, 0), 3)
            cv2.putText(output_img, f"{i+1}", (x-15, y+5), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            
            # å–å€¼
            mask = np.zeros(img.shape[:2], dtype="uint8")
            cv2.circle(mask, (x, y), int(r * (roi_scale - 0.1)), 255, -1)
            mean_val = cv2.mean(score_img, mask=mask)[0]
            s_values.append(mean_val)

    return output_img, s_values, len(final_circles)

# ==========================================
# 3. æ‹Ÿåˆå¼•æ“ (æ–°å¢è™šçº¿ç»˜å›¾é€»è¾‘)
# ==========================================
def linear_func(x, k, b): return k * x + b
def exp_decay_func(x, a, b, c): return a * np.exp(-b * x) + c
def inverse_linear(y, k, b): return (y - b) / k
def inverse_exp(y, a, b, c):
    try:
        val = (y - c) / a
        if val <= 0: return 0
        return -(1/b) * np.log(val)
    except: return 0

def auto_fit_engine(x_data, y_data):
    report = {}
    x_data = np.array(x_data); y_data = np.array(y_data)
    
    # çº¿æ€§
    s, i, r, _, _ = stats.linregress(x_data, y_data)
    report['linear_global'] = {'params':(s,i), 'r2':r**2, 'func':linear_func, 'inv_func':inverse_linear, 'name':'å…¨å±€çº¿æ€§'}
    
    # æŒ‡æ•°
    try:
        p0 = [np.max(y_data)-np.min(y_data), 0.5, np.min(y_data)]
        popt, _ = curve_fit(exp_decay_func, x_data, y_data, p0=p0, maxfev=5000)
        res = y_data - exp_decay_func(x_data, *popt)
        r2 = 1 - (np.sum(res**2)/np.sum((y_data-np.mean(y_data))**2))
        report['exp_global'] = {'params':popt, 'r2':r2, 'func':exp_decay_func, 'inv_func':inverse_exp, 'name':'æŒ‡æ•°è¡°å‡'}
    except: report['exp_global'] = {'r2':-1}
    
    # å±€éƒ¨çº¿æ€§ (æœ€å°‘ 5 ä¸ªç‚¹)
    best_r2 = -1
    min_pts = 5 # <--- ä¿®æ”¹ï¼šè‡³å°‘éœ€è¦5ä¸ªç‚¹
    
    if len(x_data) >= min_pts:
        for i in range(len(x_data) - min_pts + 1):
            for j in range(i + min_pts, len(x_data) + 1):
                sx = x_data[i:j]; sy = y_data[i:j]
                ts, ti, tr, _, _ = stats.linregress(sx, sy)
                if tr**2 > best_r2:
                    best_r2 = tr**2
                    report['best_linear_range'] = {
                        'range_text': f"{sx[0]} - {sx[-1]}", 
                        'indices':(i,j), 'params':(ts,ti), 'r2':best_r2, 
                        'func':linear_func, 'inv_func':inverse_linear,
                        'x_range': sx # ä¿å­˜xæ•°æ®ç”¨äºç”»å›¾
                    }
    else: report['best_linear_range'] = None

    if report['exp_global']['r2'] > report['linear_global']['r2'] + 0.02:
        report['recommended'] = report['exp_global']
    else:
        report['recommended'] = report['linear_global']
    return report

# ==========================================
# 4. Streamlit ç•Œé¢
# ==========================================
st.set_page_config(page_title="BioSensor Pro Max", layout="wide")
st.title("ğŸ§¬ ç”Ÿç‰©ä¼ æ„Ÿå™¨æ™ºèƒ½åˆ†æç³»ç»Ÿ")

with st.sidebar:
    st.header("âš™ï¸ å‚æ•°è®¾ç½®")
    
    analysis_mode = st.selectbox(
        "ğŸ“Š ä¿¡å·åˆ†ææ¨¡å¼", 
        ["Green Channel (G)", "Saturation (S)", "Red Channel (R)", "Blue Channel (B)", "Value (V)"],
        index=1 # é»˜è®¤ Saturation
    )
    
    conc_input = st.text_area("æ ‡å‡†å“æµ“åº¦ (mM)", "0, 0.1, 0.5, 1, 2, 4, 6, 8, 10, 15, 20")
    try: known_concs = [float(x.strip()) for x in conc_input.split(',')]
    except: known_concs = []
    
    st.markdown("---")
    rows = st.number_input("è¡Œæ•° (Rows)", 1, 10, 2)
    cols = st.number_input("åˆ—æ•° (Cols)", 1, 20, 7)

tab1, tab2 = st.tabs(["ğŸ“ å»ºç«‹æ ‡æ›²", "ğŸ§ª æ ·å“æ£€æµ‹"])
if 'fit_report' not in st.session_state: st.session_state.fit_report = None

with tab1:
    uploaded_calib = st.file_uploader("ä¸Šä¼ æ ‡å‡†å“å›¾ç‰‡", type=['jpg', 'png', 'jpeg'])
    if uploaded_calib:
        col1, col2 = st.columns([1,1])
        with col1:
            target_count = len(known_concs)
            img, vals, count = process_image(uploaded_calib, rows, cols, target_count, analysis_mode)
            st.image(img, channels="BGR", use_container_width=True, caption=f"è¯†åˆ«ç»“æœ ({count}/{target_count})")
        
        with col2:
            if count != target_count:
                st.error(f"âš ï¸ æ•°é‡ä¸åŒ¹é…ï¼éœ€è¦ {target_count}ï¼Œæ‰¾åˆ° {count}ã€‚")
            else:
                report = auto_fit_engine(known_concs, vals)
                st.session_state.fit_report = report
                rec = report['recommended']
                
                st.success(f"âœ… æ¨è: {rec['name']}")
                st.metric("RÂ²", f"{rec['r2']:.4f}")
                
                # --- ç»˜å›¾é€»è¾‘æ›´æ–° ---
                fig, ax = plt.subplots()
                xs = np.linspace(min(known_concs), max(known_concs), 100)
                
                # 1. åŸå§‹æ•°æ®ç‚¹
                ax.scatter(known_concs, vals, color='black', label='Data', zorder=5)
                
                # 2. å…¨å±€æ¨èæ›²çº¿ (å®çº¿)
                ax.plot(xs, rec['func'](xs, *rec['params']), 'r-', linewidth=2, label='Global Fit')
                
                # 3. æœ€ä½³å±€éƒ¨çº¿æ€§ (è™šçº¿)
                br = report.get('best_linear_range')
                if br and br['r2'] > report['linear_global']['r2'] + 0.01: # åªæœ‰æ¯”å…¨å±€çº¿æ€§å¥½æ‰ç”»
                    i1, i2 = br['indices']
                    # é«˜äº®é€‰ä¸­çš„ç‚¹
                    ax.scatter(known_concs[i1:i2], vals[i1:i2], s=150, facecolors='none', edgecolors='lime', lw=2, label='Best Range Pts')
                    
                    # ç”»å±€éƒ¨è™šçº¿ (å»¶é•¿ä¸€ç‚¹ç‚¹ä»¥ä¾¿çœ‹æ¸…è¶‹åŠ¿)
                    local_x = np.array(br['x_range'])
                    local_y_fit = br['func'](local_x, *br['params'])
                    ax.plot(local_x, local_y_fit, color='lime', linestyle='--', linewidth=2.5, label=f"Local Linear (RÂ²={br['r2']:.4f})")
                    
                    st.info(f"ğŸ’¡ æœ€ä½³å±€éƒ¨çº¿æ€§èŒƒå›´ ({min_pts}+ç‚¹): {br['range_text']} (RÂ²={br['r2']:.4f})")
                
                ax.legend()
                ax.set_xlabel("Concentration")
                ax.set_ylabel(f"Signal ({analysis_mode})")
                st.pyplot(fig)

with tab2:
    if not st.session_state.fit_report:
        st.info("ğŸ‘ˆ è¯·å…ˆå»ºç«‹æ ‡æ›²")
    else:
        rep = st.session_state.fit_report
        opts = {"æ™ºèƒ½æ¨è": rep['recommended'], "å…¨å±€çº¿æ€§": rep['linear_global'], "å…¨å±€éçº¿æ€§": rep['exp_global']}
        if rep.get('best_linear_range'): opts[f"æœ€ä½³çº¿æ€§ ({rep['best_linear_range']['range_text']})"] = rep['best_linear_range']
        
        sel = opts[st.selectbox("è®¡ç®—æ¨¡å‹", list(opts.keys()))]
        limit = st.slider("æ ·å“æ•°é‡", 1, rows*cols, rows*cols)
        up_test = st.file_uploader("ä¸Šä¼ æ ·å“", type=['jpg', 'png'], key='t')
        
        if up_test:
            t_img, t_vals, t_cnt = process_image(up_test, rows, cols, limit, analysis_mode)
            st.image(t_img, channels="BGR", caption=f"æ£€æµ‹ {t_cnt} ä¸ª")
            if t_cnt > 0:
                res = []
                for v in t_vals: res.append(sel['inv_func'](v, *sel['params']))
                st.dataframe({"Sample": range(1, len(res)+1), "Signal": [f"{v:.1f}" for v in t_vals], "Conc": [f"{c:.4f}" for c in res]})






